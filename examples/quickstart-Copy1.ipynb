{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7037f111-e8eb-4270-8e69-b013d075b751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urchadezaratiana/opt/anaconda3/envs/gner/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c86b85f-ab71-4918-95c5-909a79ba7158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urchadezaratiana/.local/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# available models: https://huggingface.co/urchade\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium\")\n",
    "model.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f823dbf3-2462-4a67-8c4b-9a45ec580c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marius Petipa => actor\n",
      "1822 => date\n",
      "Trilby => character\n",
      "Charles Nodier => person\n",
      "Moscow => location\n",
      "January 25/February 6 => date\n",
      "Julian/Gregorian => date\n",
      "1870 => date\n",
      "Moscow => location\n",
      "Polina Karpakova => actor\n",
      "Trilby => character\n",
      "Ludiia Geiten => actor\n",
      "Miranda => character\n",
      "Imperial Bolshoi Kamenny Theatre => location\n",
      "January 17–29, 1871 => date\n",
      "St. Petersburg => location\n",
      "Adèle Grantzow => actor\n",
      "Trilby => character\n",
      "Lev Ivanov => actor\n",
      "Count Leopold => character\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Libretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n",
    "\"\"\"\n",
    "\n",
    "labels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels, threshold=0.4)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fae3671-1047-4d53-a949-b19a95c296c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def predict_entities(self, text, labels, flat_ner=True, threshold=0.5):\n",
    "    tokens = []\n",
    "    start_token_idx_to_text_idx = []\n",
    "    end_token_idx_to_text_idx = []\n",
    "    for match in re.finditer(r'\\w+(?:[-_]\\w+)*|\\S', text):\n",
    "        tokens.append(match.group())\n",
    "        start_token_idx_to_text_idx.append(match.start())\n",
    "        end_token_idx_to_text_idx.append(match.end())\n",
    "\n",
    "    input_x = {\"tokenized_text\": tokens, \"ner\": None}\n",
    "    x = self.collate_fn([input_x], labels)\n",
    "    output = self.predict(x, flat_ner=flat_ner, threshold=threshold)\n",
    "\n",
    "    entities = []\n",
    "    for start_token_idx, end_token_idx, ent_type in output[0]:\n",
    "        start_text_idx = start_token_idx_to_text_idx[start_token_idx]\n",
    "        end_text_idx = end_token_idx_to_text_idx[end_token_idx]\n",
    "        entities.append({\n",
    "            \"start\": start_token_idx_to_text_idx[start_token_idx],\n",
    "            \"end\": end_token_idx_to_text_idx[end_token_idx],\n",
    "            \"text\": text[start_text_idx:end_text_idx],\n",
    "            \"label\": ent_type,\n",
    "        })\n",
    "    return entities\n",
    "\n",
    "\n",
    "def batch_predict_entities(self, texts, labels, flat_ner=True, threshold=0.5):\n",
    "\n",
    "    all_tokens = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = []\n",
    "        start_token_idx_to_text_idx = []\n",
    "        end_token_idx_to_text_idx = []\n",
    "        for match in re.finditer(r'\\w+(?:[-_]\\w+)*|\\S', text):\n",
    "            tokens.append(match.group())\n",
    "            start_token_idx_to_text_idx.append(match.start())\n",
    "            end_token_idx_to_text_idx.append(match.end())\n",
    "        all_tokens.append(tokens)\n",
    "\n",
    "    input_x = [{\"tokenized_text\": tk, \"ner\": None} for tk in all_tokens]\n",
    "    x = self.collate_fn(input_x, labels)\n",
    "    outputs = self.predict(x, flat_ner=flat_ner, threshold=threshold)\n",
    "\n",
    "    all_entities = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        entities = []\n",
    "        for start_token_idx, end_token_idx, ent_type in output:\n",
    "            start_text_idx = start_token_idx_to_text_idx[start_token_idx]\n",
    "            end_text_idx = end_token_idx_to_text_idx[end_token_idx]\n",
    "            entities.append({\n",
    "                \"start\": start_token_idx_to_text_idx[start_token_idx],\n",
    "                \"end\": end_token_idx_to_text_idx[end_token_idx],\n",
    "                \"text\": texts[i][start_text_idx:end_text_idx],\n",
    "                \"label\": ent_type,\n",
    "            })\n",
    "        all_entities.append(entities)\n",
    "        \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "465b378a-16cf-43b4-b39b-df3c943c5c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'start': 13, 'end': 26, 'text': 'Marius Petipa', 'label': 'actor'},\n",
       "  {'start': 41, 'end': 45, 'text': '1822', 'label': 'date'},\n",
       "  {'start': 56, 'end': 62, 'text': 'Trilby', 'label': 'character'},\n",
       "  {'start': 90, 'end': 104, 'text': 'Charles Nodier', 'label': 'person'},\n",
       "  {'start': 143, 'end': 149, 'text': 'Moscow', 'label': 'location'},\n",
       "  {'start': 178, 'end': 199, 'text': 'January 25/February 6', 'label': 'date'},\n",
       "  {'start': 235, 'end': 239, 'text': '1870', 'label': 'date'},\n",
       "  {'start': 244, 'end': 250, 'text': 'Moscow', 'label': 'location'},\n",
       "  {'start': 256, 'end': 272, 'text': 'Polina Karpakova', 'label': 'actor'},\n",
       "  {'start': 276, 'end': 282, 'text': 'Trilby', 'label': 'character'},\n",
       "  {'start': 287, 'end': 300, 'text': 'Ludiia Geiten', 'label': 'actor'},\n",
       "  {'start': 304, 'end': 311, 'text': 'Miranda', 'label': 'character'},\n",
       "  {'start': 366,\n",
       "   'end': 398,\n",
       "   'text': 'Imperial Bolshoi Kamenny Theatre',\n",
       "   'label': 'location'},\n",
       "  {'start': 402, 'end': 421, 'text': 'January 17–29, 1871', 'label': 'date'},\n",
       "  {'start': 425, 'end': 439, 'text': 'St. Petersburg', 'label': 'location'},\n",
       "  {'start': 445, 'end': 459, 'text': 'Adèle Grantzow', 'label': 'actor'},\n",
       "  {'start': 463, 'end': 469, 'text': 'Trilby', 'label': 'character'},\n",
       "  {'start': 474, 'end': 484, 'text': 'Lev Ivanov', 'label': 'actor'},\n",
       "  {'start': 488, 'end': 501, 'text': 'Count Leopold', 'label': 'character'}],\n",
       " [{'start': 13, 'end': 26, 'text': 'Marius Petipa', 'label': 'actor'},\n",
       "  {'start': 41, 'end': 45, 'text': '1822', 'label': 'date'},\n",
       "  {'start': 56, 'end': 62, 'text': 'Trilby', 'label': 'character'},\n",
       "  {'start': 90, 'end': 104, 'text': 'Charles Nodier', 'label': 'person'},\n",
       "  {'start': 143, 'end': 149, 'text': 'Moscow', 'label': 'location'},\n",
       "  {'start': 178, 'end': 199, 'text': 'January 25/February 6', 'label': 'date'},\n",
       "  {'start': 235, 'end': 239, 'text': '1870', 'label': 'date'},\n",
       "  {'start': 244, 'end': 250, 'text': 'Moscow', 'label': 'location'},\n",
       "  {'start': 256, 'end': 272, 'text': 'Polina Karpakova', 'label': 'actor'},\n",
       "  {'start': 276, 'end': 282, 'text': 'Trilby', 'label': 'character'},\n",
       "  {'start': 287, 'end': 300, 'text': 'Ludiia Geiten', 'label': 'actor'},\n",
       "  {'start': 304, 'end': 311, 'text': 'Miranda', 'label': 'character'},\n",
       "  {'start': 366,\n",
       "   'end': 398,\n",
       "   'text': 'Imperial Bolshoi Kamenny Theatre',\n",
       "   'label': 'location'},\n",
       "  {'start': 402, 'end': 421, 'text': 'January 17–29, 1871', 'label': 'date'},\n",
       "  {'start': 425, 'end': 439, 'text': 'St. Petersburg', 'label': 'location'},\n",
       "  {'start': 445, 'end': 459, 'text': 'Adèle Grantzow', 'label': 'actor'},\n",
       "  {'start': 463, 'end': 469, 'text': 'Trilby', 'label': 'character'},\n",
       "  {'start': 474, 'end': 484, 'text': 'Lev Ivanov', 'label': 'actor'},\n",
       "  {'start': 488, 'end': 501, 'text': 'Count Leopold', 'label': 'character'}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_predict_entities(model, [text, text], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482ce409-9f12-42ba-af0f-f3eaa6aa1345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 13, 'end': 26, 'text': 'Marius Petipa', 'label': 'actor'},\n",
       " {'start': 41, 'end': 45, 'text': '1822', 'label': 'date'},\n",
       " {'start': 56, 'end': 62, 'text': 'Trilby', 'label': 'character'},\n",
       " {'start': 90, 'end': 104, 'text': 'Charles Nodier', 'label': 'person'},\n",
       " {'start': 143, 'end': 149, 'text': 'Moscow', 'label': 'location'},\n",
       " {'start': 178, 'end': 199, 'text': 'January 25/February 6', 'label': 'date'},\n",
       " {'start': 235, 'end': 239, 'text': '1870', 'label': 'date'},\n",
       " {'start': 244, 'end': 250, 'text': 'Moscow', 'label': 'location'},\n",
       " {'start': 256, 'end': 272, 'text': 'Polina Karpakova', 'label': 'actor'},\n",
       " {'start': 276, 'end': 282, 'text': 'Trilby', 'label': 'character'},\n",
       " {'start': 287, 'end': 300, 'text': 'Ludiia Geiten', 'label': 'actor'},\n",
       " {'start': 304, 'end': 311, 'text': 'Miranda', 'label': 'character'},\n",
       " {'start': 366,\n",
       "  'end': 398,\n",
       "  'text': 'Imperial Bolshoi Kamenny Theatre',\n",
       "  'label': 'location'},\n",
       " {'start': 402, 'end': 421, 'text': 'January 17–29, 1871', 'label': 'date'},\n",
       " {'start': 425, 'end': 439, 'text': 'St. Petersburg', 'label': 'location'},\n",
       " {'start': 445, 'end': 459, 'text': 'Adèle Grantzow', 'label': 'actor'},\n",
       " {'start': 463, 'end': 469, 'text': 'Trilby', 'label': 'character'},\n",
       " {'start': 474, 'end': 484, 'text': 'Lev Ivanov', 'label': 'actor'},\n",
       " {'start': 488, 'end': 501, 'text': 'Count Leopold', 'label': 'character'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_entities(model, text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d1377-f073-485f-bd4f-35b5750ba020",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict_entities(self, text, labels, flat_ner=True, threshold=0.5):\n",
    "        tokens = []\n",
    "        start_token_idx_to_text_idx = []\n",
    "        end_token_idx_to_text_idx = []\n",
    "        for match in re.finditer(r'\\w+(?:[-_]\\w+)*|\\S', text):\n",
    "            tokens.append(match.group())\n",
    "            start_token_idx_to_text_idx.append(match.start())\n",
    "            end_token_idx_to_text_idx.append(match.end())\n",
    "\n",
    "        input_x = {\"tokenized_text\": tokens, \"ner\": None}\n",
    "        x = self.collate_fn([input_x], labels)\n",
    "        output = self.predict(x, flat_ner=flat_ner, threshold=threshold)\n",
    "\n",
    "        entities = []\n",
    "        for start_token_idx, end_token_idx, ent_type in output[0]:\n",
    "            start_text_idx = start_token_idx_to_text_idx[start_token_idx]\n",
    "            end_text_idx = end_token_idx_to_text_idx[end_token_idx]\n",
    "            entities.append({\n",
    "                \"start\": start_token_idx_to_text_idx[start_token_idx],\n",
    "                \"end\": end_token_idx_to_text_idx[end_token_idx],\n",
    "                \"text\": text[start_text_idx:end_text_idx],\n",
    "                \"label\": ent_type,\n",
    "            })\n",
    "        return entities\n",
    "\n",
    "    def evaluate(self, test_data, flat_ner=False, threshold=0.5, batch_size=12, entity_types=None):\n",
    "        self.eval()\n",
    "        data_loader = self.create_dataloader(test_data, batch_size=batch_size, entity_types=entity_types, shuffle=False)\n",
    "        device = next(self.parameters()).device\n",
    "        all_preds = []\n",
    "        all_trues = []\n",
    "        for x in data_loader:\n",
    "            for k, v in x.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    x[k] = v.to(device)\n",
    "            batch_predictions = self.predict(x, flat_ner, threshold)\n",
    "            all_preds.extend(batch_predictions)\n",
    "            all_trues.extend(x[\"entities\"])\n",
    "        evaluator = Evaluator(all_trues, all_preds)\n",
    "        out, f1 = evaluator.evaluate()\n",
    "        return out, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
